{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc95cf2b",
   "metadata": {},
   "source": [
    "# Część 1: Podstawy HTML i XML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4a6603",
   "metadata": {},
   "source": [
    "1. Tagi, atrybuty, i elementy:\n",
    "\n",
    "* Tagi to podstawowe składniki języka HTML i XML. Są one umieszczane w nawiasach ostrokątnych, np. &lt;html>, &lt;body>,  &lt;div>.\n",
    "* Atrybuty dostarczają dodatkowych informacji o tagach. Przykład: w tagu &lt;a href=\"https://example.com\"&gt;, href jest atrybutem definiującym adres URL linku.\n",
    "* Elementy składają się z otwierającego tagu, zawartości i zamykającego tagu. Na przykład, &lt;p>To jest paragraf.&lt;/p>, &lt;a> href=hiperłącze &lt;/a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc4be8a",
   "metadata": {},
   "source": [
    "2. Nagłówki w HTML\n",
    "* Nagłówki to elementy HTML używane do organizacji i strukturyzacji treści na stronie internetowej. Są one oznaczane tagami od &lt;h1> do &lt;h6>.\n",
    "* &lt;h1> reprezentuje najważniejszy nagłówek na stronie, zwykle tytuł lub główny punkt strony, a &lt;h6> jest najmniej istotnym nagłówkiem.\n",
    "* Użycie nagłówków pomaga w tworzeniu hierarchii informacji na stronie, co jest ważne zarówno dla użytkowników, jak i dla wyszukiwarek internetowych.\n",
    "Przykład:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5d158141",
   "metadata": {},
   "source": [
    "<h1>Tytuł główny strony</h1>\n",
    "<h2>Podsekcja 1</h2>\n",
    "<p>Treść podsekcji 1...</p>\n",
    "<h2>Podsekcja 2</h2>\n",
    "<p>Treść podsekcji 2...</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92a8333",
   "metadata": {},
   "source": [
    "3. HTML a XML:\n",
    "* HTML jest używany głównie do tworzenia stron internetowych i jest bardziej elastyczny co do składni.\n",
    "XML służy do przechowywania i przesyłania danych i wymaga ścisłego przestrzegania zasad dobrze sformowanego dokumentu."
   ]
  },
  {
   "cell_type": "code",
   "id": "6ab8a684",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T15:13:04.765533Z",
     "start_time": "2024-11-15T15:13:04.758955Z"
    }
   },
   "source": [
    "# Tworzenie przykładowego pliku XML\n",
    "xml_content = \"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "<library>\n",
    "    <book>\n",
    "        <title>Przygody Tomka Sawyera</title>\n",
    "        <author>Mark Twain</author>\n",
    "        <year>1876</year>\n",
    "    </book>\n",
    "    <book>\n",
    "        <title>Pan Tadeusz</title>\n",
    "        <author>Adam Mickiewicz</author>\n",
    "        <year>1834</year>\n",
    "    </book>\n",
    "</library>\n",
    "\"\"\""
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "e093e720",
   "metadata": {},
   "source": [
    "4. Narzędzia do inspekcji strony:\n",
    "\n",
    "Narzędzia deweloperskie w przeglądarkach internetowych (takie jak Chrome, Firefox, Edge) pozwalają na oglądanie struktury HTML, stylów CSS i skryptów JavaScript strony. Można je otworzyć klikając prawym przyciskiem myszy na stronie i wybierając \"Zbadaj\" lub naciskając F12."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90449daa",
   "metadata": {},
   "source": [
    "**Ćwiczenie:**\n",
    "\n",
    "Należy utworzyć bardzo prostą stronę internetową zawierającą tytuł, kilka nagłówków i paragrafów. Jeden paragraf ma zawierać hiperłącze do strony MiMUW. Utworzoną stronę proszę zapisać w pliku i podejrzeć w przeglądarce z wykorzystaniem \"Zbadaj\" (zazwyczaj F12).\n",
    "\n",
    "Ewentualnie można skorzystać z poniższej przykładowej implementacji (w zależności od znajomości HTML). "
   ]
  },
  {
   "cell_type": "code",
   "id": "aeebe715",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T12:10:00.632225Z",
     "start_time": "2024-11-22T12:10:00.629562Z"
    }
   },
   "source": [
    "# Tworzenie przykładowej strony HTML (do późniejszego przetwarzania przy użyciu BeautifulSoup)\n",
    "html_content = \"\"\"\n",
    "<!DOCTYPE html> \n",
    "<html>\n",
    "<head>\n",
    "    <title>Page title - Webscraping</title>\n",
    "</head>\n",
    "<body>\n",
    "    <h1>Level 1 header</h1>\n",
    "    <h2>Level 2 header</h2>\n",
    "    <p>A paragraph.</p>\n",
    "    <p>Next paragraph with <a href=\"https://www.mimuw.edu.pl/\">links</a> at the end.</p>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\""
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "d7563ca6-9e60-4e04-a575-012ea01e8304",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T12:10:01.484364Z",
     "start_time": "2024-11-22T12:10:01.481439Z"
    }
   },
   "source": [
    "# tu wpisz rozwiązanie\n",
    "html_file_path = \"test.html\"\n",
    "with open(html_file_path, \"w\") as html_file:\n",
    "    html_file.write(html_content)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "bd083725",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T15:13:08.614520Z",
     "start_time": "2024-11-15T15:13:08.610463Z"
    }
   },
   "source": [
    "# Po zapisie strony możemy otworzyć ją (domyślnie powinna otworzyć się w przeglądarce internetowej) i obejrzeć w jaki sposób \n",
    "# wygląda i widoczna jest w trybie inspektora (F12)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "0f5c16f8",
   "metadata": {},
   "source": [
    "# Część 2: Parsowanie HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fe75b4",
   "metadata": {},
   "source": [
    "W tej części skupimy się na narzędziach wykorzystywanych do parsowania treści HTML. Bardzo popularnym pakietem jest Beautiful Soup. Jest to pakiet, który służy do parsowania dokumentów HTML i XML. Jest szczególnie użyteczny w web scrapingu, czyli procesie ekstrakcji danych z stron internetowych."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cebc84",
   "metadata": {},
   "source": [
    "Napiszmy więc kod, w którym wykorzystamy pakiet BeautifulSoup do analizy naszej strony i wyszukania w niej nagłówków, tytułów oraz paragrafów. Przekonamy się, jak łatwo można przetwarzać HTML."
   ]
  },
  {
   "cell_type": "code",
   "id": "8c7f5c6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T12:12:28.717107Z",
     "start_time": "2024-11-22T12:12:28.655466Z"
    }
   },
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Wczytywanie zawartości strony HTML\n",
    "with open(html_file_path, 'r') as file:\n",
    "    html_page = file.read()"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "5d71c800",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T12:12:30.147612Z",
     "start_time": "2024-11-22T12:12:30.142227Z"
    }
   },
   "source": [
    "html_page"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n<!DOCTYPE html> \\n<html>\\n<head>\\n    <title>Page title - Webscraping</title>\\n</head>\\n<body>\\n    <h1>Level 1 header</h1>\\n    <h2>Level 2 header</h2>\\n    <p>A paragraph.</p>\\n    <p>Next paragraph with <a href=\"https://www.mimuw.edu.pl/\">links</a> at the end.</p>\\n</body>\\n</html>\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "271ab001",
   "metadata": {},
   "source": [
    "Utworzymy obiekt BeautifulSoup - jako parser wybieramy wbudowany (nie wymagający instalacji/importu dodatkowych pakietów) parser html.\n",
    "Wybór parsera zależny jest od założeń oraz wymagań projektów, jednakże dla tak małych stron html.parser jest wystarczający.\n",
    "W przypadku znacznie większych stron warto rozważyć wykorzystanie lxml, który jest szybszy (wymaga jednak instalacji dodatkowych zależności). Więcej na ten temat można poczytać w dokumentacji:\n",
    "https://www.crummy.com/software/BeautifulSoup/bs4/doc/#installing-a-parser"
   ]
  },
  {
   "cell_type": "code",
   "id": "00bdd475",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T12:12:35.030404Z",
     "start_time": "2024-11-22T12:12:35.025935Z"
    }
   },
   "source": [
    "soup = BeautifulSoup(html_page, 'html.parser')"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "ace7a1b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T12:12:36.386445Z",
     "start_time": "2024-11-22T12:12:36.383052Z"
    }
   },
   "source": [
    "soup"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "<!DOCTYPE html>\n",
       "\n",
       "<html>\n",
       "<head>\n",
       "<title>Page title - Webscraping</title>\n",
       "</head>\n",
       "<body>\n",
       "<h1>Level 1 header</h1>\n",
       "<h2>Level 2 header</h2>\n",
       "<p>A paragraph.</p>\n",
       "<p>Next paragraph with <a href=\"https://www.mimuw.edu.pl/\">links</a> at the end.</p>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "ff3127db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T15:15:55.620251Z",
     "start_time": "2024-11-15T15:15:55.617705Z"
    }
   },
   "source": [
    "# I bardziej czytelnie\n",
    "print(soup.prettify())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   Page title - Webscraping\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <h1>\n",
      "   Level 1 header\n",
      "  </h1>\n",
      "  <h2>\n",
      "   Level 2 header\n",
      "  </h2>\n",
      "  <p>\n",
      "   A paragraph.\n",
      "  </p>\n",
      "  <p>\n",
      "   Next paragraph with\n",
      "   <a href=\"https://www.mimuw.edu.pl/\">\n",
      "    links\n",
      "   </a>\n",
      "   at the end.\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "05244ba1",
   "metadata": {},
   "source": [
    "A więc mamy już sparsowaną treść naszej strony - możemy więc przejść do wyszukiwania na niej informacji. W naszym przypadku (choć jest ich niewiele) - możemy pobrać tytuł, nagłówki oraz paragrafy. Spróbujemy również pobrać link do strony MiMUW."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75eaf87b",
   "metadata": {},
   "source": [
    "Tytuł strony"
   ]
  },
  {
   "cell_type": "code",
   "id": "5e9a59a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T12:13:06.867849Z",
     "start_time": "2024-11-22T12:13:06.864479Z"
    }
   },
   "source": [
    "# Wyszukiwanie tytułu strony\n",
    "page_title = soup.title"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "6d259de2",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-11-22T12:13:07.355902Z",
     "start_time": "2024-11-22T12:13:07.350930Z"
    }
   },
   "source": [
    "page_title"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>Page title - Webscraping</title>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "360c88e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T12:13:09.340606Z",
     "start_time": "2024-11-22T12:13:09.336990Z"
    }
   },
   "source": [
    "page_title.string"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Page title - Webscraping'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "942ef099",
   "metadata": {},
   "source": [
    "Nagłówki - h1, h2. Wykorzystamy metody\n",
    "* find() - służy do wyszukiwania pierwszego wystąpienia danego tagu lub tagów spełniających określone kryteria.\n",
    "* find_all() - znajduje wszystkie tagi spełniające te kryteria."
   ]
  },
  {
   "cell_type": "code",
   "id": "560cbe4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T12:13:17.526922Z",
     "start_time": "2024-11-22T12:13:17.524036Z"
    }
   },
   "source": [
    "# Wyszukiwanie wszystkich nagłówków h1 i h2\n",
    "headers_h1 = soup.find_all('h1')"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "d9b84b8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T12:13:18.987912Z",
     "start_time": "2024-11-22T12:13:18.803850Z"
    }
   },
   "source": [
    "headers_h1.string # Nie działa - dlaczego? find_all zwraca listę"
   ],
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ResultSet object has no attribute 'string'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m headers_h1\u001B[38;5;241m.\u001B[39mstring\n",
      "File \u001B[0;32m/opt/anaconda3/envs/Kurs-programowania-w-Pythonie/lib/python3.11/site-packages/bs4/element.py:2433\u001B[0m, in \u001B[0;36mResultSet.__getattr__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   2431\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getattr__\u001B[39m(\u001B[38;5;28mself\u001B[39m, key):\n\u001B[1;32m   2432\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Raise a helpful exception to explain a common code fix.\"\"\"\u001B[39;00m\n\u001B[0;32m-> 2433\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\n\u001B[1;32m   2434\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mResultSet object has no attribute \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m. You\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mre probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m key\n\u001B[1;32m   2435\u001B[0m     )\n",
      "\u001B[0;31mAttributeError\u001B[0m: ResultSet object has no attribute 'string'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "5952b641",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T12:13:21.711691Z",
     "start_time": "2024-11-22T12:13:21.708310Z"
    }
   },
   "source": [
    "headers_h1[0].string"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Level 1 header'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "87e903ec",
   "metadata": {},
   "source": [
    "No ale w naszym przypadku mamy przecież 1 element h1 (h2 również), a więc w zupełności wystarczyłoby find. \"W naszym przypadku\", gdyż zazwyczaj nie znamy strony i może ona zawierać setki różnego rodzaju tagów. Bezpieczniej więc skorzystać z find_all."
   ]
  },
  {
   "cell_type": "code",
   "id": "dae25258",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T12:13:33.586846Z",
     "start_time": "2024-11-22T12:13:33.583838Z"
    }
   },
   "source": [
    "# Dla porównania - find\n",
    "headers_h2 = soup.find('h2')"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "8869649e",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-11-22T12:13:33.975552Z",
     "start_time": "2024-11-22T12:13:33.971833Z"
    }
   },
   "source": [
    "headers_h2.string # Tutaj już w porządku"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Level 2 header'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "id": "bf0ec50b",
   "metadata": {},
   "source": [
    "Wyszukiwanie wszystkich paragrafów"
   ]
  },
  {
   "cell_type": "code",
   "id": "3844e7d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T12:13:36.095717Z",
     "start_time": "2024-11-22T12:13:36.093244Z"
    }
   },
   "source": [
    "# Wyszukiwanie wszystkich paragrafów\n",
    "paragraphs = soup.find_all('p')"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "5b41cedf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T12:13:36.663934Z",
     "start_time": "2024-11-22T12:13:36.659810Z"
    }
   },
   "source": [
    "paragraphs"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p>A paragraph.</p>,\n",
       " <p>Next paragraph with <a href=\"https://www.mimuw.edu.pl/\">links</a> at the end.</p>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "1e8733d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T12:13:39.843904Z",
     "start_time": "2024-11-22T12:13:39.841231Z"
    }
   },
   "source": [
    "print([p.string for p in paragraphs]) # Pod indeksem 1 mamy None, dlaczego?"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A paragraph.', None]\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "b9742cf9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T12:13:42.635579Z",
     "start_time": "2024-11-22T12:13:42.633177Z"
    }
   },
   "source": [
    "paragraphs[1].string"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "30273683",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T12:13:42.925744Z",
     "start_time": "2024-11-22T12:13:42.922796Z"
    }
   },
   "source": [
    "paragraphs[1] # Ponieważ w paragrafie znajduje się tag a. Ten z kolei ma atrybut href i jakąś przypisną mu wartość."
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p>Next paragraph with <a href=\"https://www.mimuw.edu.pl/\">links</a> at the end.</p>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "2f8c169f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T12:13:46.920894Z",
     "start_time": "2024-11-22T12:13:46.917993Z"
    }
   },
   "source": [
    "# Tutaj postępujemy w następujący sposób\n",
    "paragraphs[1].a"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a href=\"https://www.mimuw.edu.pl/\">links</a>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "61ba9e33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T12:13:47.243969Z",
     "start_time": "2024-11-22T12:13:47.240707Z"
    }
   },
   "source": [
    "# Lub\n",
    "paragraphs[1].find('a')"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a href=\"https://www.mimuw.edu.pl/\">links</a>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "289640d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T12:13:47.813519Z",
     "start_time": "2024-11-22T12:13:47.810179Z"
    }
   },
   "source": [
    "# Lub \n",
    "paragraphs[1].find_all('a')"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"https://www.mimuw.edu.pl/\">links</a>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "id": "3bd6e833",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T15:16:39.423420Z",
     "start_time": "2024-11-15T15:16:39.420157Z"
    }
   },
   "source": [
    "# Lub - możliwości jest bardzo dużo\n",
    "# Select - umożliwia wyszukiwanie elementów za pomocą selektorów CSS.\n",
    "paragraphs[1].select('a')"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"https://www.mimuw.edu.pl/\">links</a>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "id": "71c92f71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T15:16:39.722244Z",
     "start_time": "2024-11-15T15:16:39.718536Z"
    }
   },
   "source": [
    "# A następnie odwołujemy się do atrybutu href i mamy hiperłącze do MiMUW :)\n",
    "print(paragraphs[1].a['href'])\n",
    "print(paragraphs[1].find('a')['href'])\n",
    "print(paragraphs[1].find_all('a')[0]['href'])\n",
    "print(paragraphs[1].select('a')[0]['href'])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.mimuw.edu.pl/\n",
      "https://www.mimuw.edu.pl/\n",
      "https://www.mimuw.edu.pl/\n",
      "https://www.mimuw.edu.pl/\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "id": "a42dc6b7",
   "metadata": {},
   "source": [
    "Zaprezentowanych zostanie teraz kilka innych przydatnych metod z ich wykorzystaniem - na przykładzie naszej strony"
   ]
  },
  {
   "cell_type": "code",
   "id": "a1a0907b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T12:14:30.053452Z",
     "start_time": "2024-11-22T12:14:30.050782Z"
    }
   },
   "source": [
    "# find() - wyszukuje pierwszy paragraf\n",
    "first_paragraph = soup.find('p').text"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "id": "5a8be6b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T12:14:31.175404Z",
     "start_time": "2024-11-22T12:14:31.173185Z"
    }
   },
   "source": [
    "# find_all() - znajduje wszystkie paragrafy\n",
    "all_paragraphs = [p.text for p in soup.find_all('p')]"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "id": "72a43d51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T12:15:20.669471Z",
     "start_time": "2024-11-22T12:15:20.666174Z"
    }
   },
   "source": [
    "# select() - wybiera wszystkie linki (tagi a) w dokumencie\n",
    "all_links = soup.select('a')"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "id": "8f0aeb71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T12:15:21.190283Z",
     "start_time": "2024-11-22T12:15:21.188135Z"
    }
   },
   "source": [
    "# select_one() - wybiera pierwszy tag h1\n",
    "first_h1 = soup.select_one('h1').text"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "id": "89c0a6a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T12:15:21.648636Z",
     "start_time": "2024-11-22T12:15:21.646440Z"
    }
   },
   "source": [
    "# find_parent() - znajduje rodzica pierwszego linku (w tym przypadku paragraf)\n",
    "parent_of_first_link = soup.find('a').find_parent().text"
   ],
   "outputs": [],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "id": "cbb35405",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T12:14:43.677286Z",
     "start_time": "2024-11-22T12:14:43.675303Z"
    }
   },
   "source": [
    "# find_next_sibling() - znajduje następujące rodzeństwo po pierwszym nagłówku h1 (w tym przypadku h2)\n",
    "next_sibling_of_h1 = soup.find('h1').find_next_sibling().text"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "id": "ec3cbd03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T12:14:44.349179Z",
     "start_time": "2024-11-22T12:14:44.347379Z"
    }
   },
   "source": [
    "# Atrybuty - pobiera atrybut href pierwszego linku\n",
    "first_link_href = soup.find('a')['href']"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "id": "28d615f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T12:14:44.740670Z",
     "start_time": "2024-11-22T12:14:44.738098Z"
    }
   },
   "source": [
    "# Wyniki\n",
    "results = {\n",
    "    \"Pierwszy paragraf\": first_paragraph,\n",
    "    \"Wszystkie paragrafy\": all_paragraphs,\n",
    "    \"Wszystkie linki\": [link['href'] for link in all_links],\n",
    "    \"Pierwszy nagłówek h1\": first_h1,\n",
    "    \"Rodzic pierwszego linku\": parent_of_first_link,\n",
    "    \"Następne rodzeństwo po h1\": next_sibling_of_h1,\n",
    "    \"Href pierwszego linku\": first_link_href\n",
    "}\n"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "id": "de752611",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T15:16:41.949747Z",
     "start_time": "2024-11-15T15:16:41.945531Z"
    }
   },
   "source": [
    "results"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Pierwszy paragraf': 'A paragraph.',\n",
       " 'Wszystkie paragrafy': ['A paragraph.',\n",
       "  'Next paragraph with links at the end.'],\n",
       " 'Wszystkie linki': ['https://www.mimuw.edu.pl/'],\n",
       " 'Pierwszy nagłówek h1': 'Level 1 header',\n",
       " 'Rodzic pierwszego linku': 'Next paragraph with links at the end.',\n",
       " 'Następne rodzeństwo po h1': 'Level 2 header',\n",
       " 'Href pierwszego linku': 'https://www.mimuw.edu.pl/'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "markdown",
   "id": "d51abffb",
   "metadata": {},
   "source": [
    "Select vs find\n",
    "\n",
    "* find i find_all skupiają się na atrybutach i nazwach tagów.\n",
    "* select i select_one zapewniają większą elastyczność dzięki wykorzystaniu selektorów CSS, co pozwala na bardziej złożone zapytania."
   ]
  },
  {
   "cell_type": "code",
   "id": "91accf7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T12:16:39.232865Z",
     "start_time": "2024-11-22T12:16:39.229955Z"
    }
   },
   "source": [
    "html_content = \"\"\"\n",
    "<div>\n",
    "    <p class=\"text\">Pierwszy paragraf</p>\n",
    "    <p class=\"text\">Drugi paragraf</p>\n",
    "    <p id=\"special\">Trzeci paragraf</p>\n",
    "</div>\n",
    "\"\"\""
   ],
   "outputs": [],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "id": "82e4aa63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T12:16:39.675248Z",
     "start_time": "2024-11-22T12:16:39.672355Z"
    }
   },
   "source": [
    "soup2 = BeautifulSoup(html_content, 'html.parser')"
   ],
   "outputs": [],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "id": "92d2b6dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T12:17:49.892982Z",
     "start_time": "2024-11-22T12:17:49.890496Z"
    }
   },
   "source": [
    "# Dla tak zdefiniowanej strony mamy:\n",
    "first_paragraph = soup2.find('p')  # Znajduje pierwszy paragraf\n",
    "all_paragraphs = soup2.find_all('p')  # Znajduje wszystkie paragrafy\n",
    "special_paragraph = soup2.select_one('#special')  # Znajduje paragraf z ID 'special'\n",
    "text_paragraphs = soup2.select('p.text')  # Znajduje paragrafy z klasą 'text'"
   ],
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T12:18:04.026658Z",
     "start_time": "2024-11-22T12:18:04.021515Z"
    }
   },
   "cell_type": "code",
   "source": "first_paragraph",
   "id": "281431969f84b7b4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p class=\"text\">Pierwszy paragraf</p>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T12:18:17.930675Z",
     "start_time": "2024-11-22T12:18:17.927292Z"
    }
   },
   "cell_type": "code",
   "source": "special_paragraph",
   "id": "3a7584ac1186069a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p id=\"special\">Trzeci paragraf</p>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T12:18:23.953427Z",
     "start_time": "2024-11-22T12:18:23.949964Z"
    }
   },
   "cell_type": "code",
   "source": "text_paragraphs",
   "id": "98c1da0049da19d8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"text\">Pierwszy paragraf</p>, <p class=\"text\">Drugi paragraf</p>]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T12:18:10.203182Z",
     "start_time": "2024-11-22T12:18:10.199648Z"
    }
   },
   "cell_type": "code",
   "source": "all_paragraphs",
   "id": "57d534f25133051e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"text\">Pierwszy paragraf</p>,\n",
       " <p class=\"text\">Drugi paragraf</p>,\n",
       " <p id=\"special\">Trzeci paragraf</p>]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "id": "19cbaeb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T12:17:50.231618Z",
     "start_time": "2024-11-22T12:17:50.227694Z"
    }
   },
   "source": [
    "text_paragraphs"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"text\">Pierwszy paragraf</p>, <p class=\"text\">Drugi paragraf</p>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 43
  },
  {
   "cell_type": "markdown",
   "id": "d4c90a5d",
   "metadata": {},
   "source": [
    "Aby osiągnąć za pomocą find znalezienie paragrafów z klasy text musimy wykorzystać argument _class:"
   ]
  },
  {
   "cell_type": "code",
   "id": "0c3dd912",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T12:17:34.352198Z",
     "start_time": "2024-11-22T12:17:34.348692Z"
    }
   },
   "source": [
    "text_paragraphs = soup2.find_all('p', class_='text')\n",
    "\n",
    "text_paragraphs"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"text\">Pierwszy paragraf</p>, <p class=\"text\">Drugi paragraf</p>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "id": "2e154734",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-11-15T15:16:44.234007Z",
     "start_time": "2024-11-15T15:16:44.231353Z"
    }
   },
   "source": [
    "# Ewentualnie\n",
    "soup2.find_all('p', attrs=[{\"class\": \"text\"}])"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "id": "6dd19c2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T15:16:44.480522Z",
     "start_time": "2024-11-15T15:16:44.476810Z"
    }
   },
   "source": [
    "# Warto pokazać tutaj również wykorzystanie id (attrs)\n",
    "soup2.find_all('p', {\"id\": \"special\"})"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p id=\"special\">Trzeci paragraf</p>]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 44
  },
  {
   "cell_type": "markdown",
   "id": "6f9a5cae",
   "metadata": {},
   "source": [
    "# Część 3: Pakiet requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9c25f9",
   "metadata": {},
   "source": [
    "Wiedza z poprzednich części będzie teraz wykorzystana w praktyce. Zanim przejdziemy do ćwiczenia zapoznamy się z pakietem requests, który umożliwi nam wysyłanie żądań HTTP. Obsługuje on wszystkie popularne metody HTTP, takie jak GET, POST, PUT, DELETE...\n",
    "Inne pakiety tego typu to np. wbudowane urllib oraz http.client. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93393f9e",
   "metadata": {},
   "source": [
    "Aby korzystać z requests, najpierw trzeba zainstalować pakiet. Możemy to zrobić za pomocą pip (systemu zarządzania pakietami w Pythonie):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66a1c36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "id": "63076652",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T12:18:45.950436Z",
     "start_time": "2024-11-22T12:18:45.875547Z"
    }
   },
   "source": [
    "import requests"
   ],
   "outputs": [],
   "execution_count": 48
  },
  {
   "cell_type": "markdown",
   "id": "f13651da",
   "metadata": {},
   "source": [
    "POST Request\n",
    "\n",
    "Zapytanie POST służy do wysyłania danych do serwera, na przykład przy przesyłaniu formularza. Niekótre z metod przetestujemy na stronie https://httpbin.org/#/, która umożliwia testowanie zapytań."
   ]
  },
  {
   "cell_type": "code",
   "id": "7349d4e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T12:18:57.864189Z",
     "start_time": "2024-11-22T12:18:57.248804Z"
    }
   },
   "source": [
    "payload = {'key1': 'value1', 'key2': 'value2'}\n",
    "\n",
    "response = requests.post('https://httpbin.org/post', data=payload)\n",
    "print(response.text)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"args\": {}, \n",
      "  \"data\": \"\", \n",
      "  \"files\": {}, \n",
      "  \"form\": {\n",
      "    \"key1\": \"value1\", \n",
      "    \"key2\": \"value2\"\n",
      "  }, \n",
      "  \"headers\": {\n",
      "    \"Accept\": \"*/*\", \n",
      "    \"Accept-Encoding\": \"gzip, deflate, br\", \n",
      "    \"Content-Length\": \"23\", \n",
      "    \"Content-Type\": \"application/x-www-form-urlencoded\", \n",
      "    \"Host\": \"httpbin.org\", \n",
      "    \"User-Agent\": \"python-requests/2.32.3\", \n",
      "    \"X-Amzn-Trace-Id\": \"Root=1-674076b1-78ccdada2ad59dff28ca25b9\"\n",
      "  }, \n",
      "  \"json\": null, \n",
      "  \"origin\": \"193.0.108.41\", \n",
      "  \"url\": \"https://httpbin.org/post\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "id": "c781b3eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T12:19:19.765439Z",
     "start_time": "2024-11-22T12:19:19.762124Z"
    }
   },
   "source": [
    "response # Zwraca kod żądania. Więcej można poczytać na przykład tutaj: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 50
  },
  {
   "cell_type": "markdown",
   "id": "b5b9fa9d",
   "metadata": {},
   "source": [
    "Krótka interpretacja: \n",
    "\n",
    "args: pusty obiekt, co oznacza, że do żądania POST nie zostały dołączone żadne parametry URL\n",
    "\n",
    "data: jest puste, co wskazuje, że żadne dane nie zostały wysłane w ciele żądania w formacie innym niż formularz\n",
    "\n",
    "files: jest puste - w żądaniu POST nie wysłano żadnych plików\n",
    "\n",
    "form: pokazuje dane, które zostały przesłane za pomocą żądania POST. W tym przypadku są to klucze i wartości podane w metodzie post.\n",
    "\n",
    "headers: zawiera nagłówki przesłane razem z żądaniem. Są one automatycznie dodawane przez pakiet requests lub serwer. Poniżej opis kilku z nich.\n",
    "\n",
    "* Host: nazwa hosta, do którego skierowane jest żądanie\n",
    "* User-Agent: identyfikuje klienta wykonującego żądanie, tutaj python-requests/2.31.0 oznacza, że wykorzystano pakiet requests w Pythonie.\n",
    "\n",
    "origin: pokazuje adres IP, z którego wysłano żądanie.\n",
    "\n",
    "url: adres URL, na który wysłano żądanie POST."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3c8287",
   "metadata": {},
   "source": [
    "GET Request\n",
    "\n",
    "Zapytanie GET służy do pobierania danych z określonego zasobu, a więc jest ono najbardziej przydatne podczas webscrapingu."
   ]
  },
  {
   "cell_type": "code",
   "id": "ebd34185",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T12:19:44.979681Z",
     "start_time": "2024-11-22T12:19:44.467929Z"
    }
   },
   "source": [
    "response = requests.get('https://example.com')\n",
    "print(response.text)  # Wyświetla zawartość strony"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!doctype html>\n",
      "<html>\n",
      "<head>\n",
      "    <title>Example Domain</title>\n",
      "\n",
      "    <meta charset=\"utf-8\" />\n",
      "    <meta http-equiv=\"Content-type\" content=\"text/html; charset=utf-8\" />\n",
      "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n",
      "    <style type=\"text/css\">\n",
      "    body {\n",
      "        background-color: #f0f0f2;\n",
      "        margin: 0;\n",
      "        padding: 0;\n",
      "        font-family: -apple-system, system-ui, BlinkMacSystemFont, \"Segoe UI\", \"Open Sans\", \"Helvetica Neue\", Helvetica, Arial, sans-serif;\n",
      "        \n",
      "    }\n",
      "    div {\n",
      "        width: 600px;\n",
      "        margin: 5em auto;\n",
      "        padding: 2em;\n",
      "        background-color: #fdfdff;\n",
      "        border-radius: 0.5em;\n",
      "        box-shadow: 2px 3px 7px 2px rgba(0,0,0,0.02);\n",
      "    }\n",
      "    a:link, a:visited {\n",
      "        color: #38488f;\n",
      "        text-decoration: none;\n",
      "    }\n",
      "    @media (max-width: 700px) {\n",
      "        div {\n",
      "            margin: 0 auto;\n",
      "            width: auto;\n",
      "        }\n",
      "    }\n",
      "    </style>    \n",
      "</head>\n",
      "\n",
      "<body>\n",
      "<div>\n",
      "    <h1>Example Domain</h1>\n",
      "    <p>This domain is for use in illustrative examples in documents. You may use this\n",
      "    domain in literature without prior coordination or asking for permission.</p>\n",
      "    <p><a href=\"https://www.iana.org/domains/example\">More information...</a></p>\n",
      "</div>\n",
      "</body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "id": "b8e4db49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T12:19:45.897152Z",
     "start_time": "2024-11-22T12:19:45.893947Z"
    }
   },
   "source": [
    "type(response.text)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 52
  },
  {
   "cell_type": "markdown",
   "id": "a056cced",
   "metadata": {},
   "source": [
    "A więc możemy pobrać zawartość strony (jej treść HTML) z wykorzystaniem requests. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a500483",
   "metadata": {},
   "source": [
    "**Ćwiczenie:**\n",
    "Wyszukiwanie poszczególnych elementów na stronie\n",
    "\n",
    "W tym zadaniu proszę (wykorzystując Beautiful Soup) wypisać treść nagłówków, paragrafaów oraz zlokalizować hiperłącza znajdujące się na stronie https://example.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea9f577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tu wpisz rozwiązanie\n",
    "results = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4b75e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9a330f",
   "metadata": {},
   "source": [
    "Nagłówki\n",
    "\n",
    "Możemy sami definiować nagłówki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae5a5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'User-Agent': 'Marcin'}\n",
    "payload = {'key1': 'value1', 'key2': 'value2'}\n",
    "\n",
    "response = requests.post('https://httpbin.org/post', data=payload, headers=headers)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541af7eb",
   "metadata": {},
   "source": [
    "Teraz sami zdefiniowaliśmy nagłówek i widoczne jest to w odpowiedzi. Niekiedy działanie takie może być bardzo przydatne:)\n",
    "\n",
    " \"User-Agent\": \"Marcin\", "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66aaa444",
   "metadata": {},
   "source": [
    "Ciasteczka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd62b234",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get('http://example.com')\n",
    "print(response.cookies)  # Wyświetla ciasteczka z odpowiedzi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1645afab",
   "metadata": {},
   "source": [
    "# Część 4: FastAPI i requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8723532d",
   "metadata": {},
   "source": [
    "FastAPI to nowoczesny, szybki (wysokowydajny) framework do tworzenia API z Pythonem 3.7+ oparty na standardowych typach Pythona. Jest on używany do tworzenia interfejsów API*\n",
    "\n",
    "*  *https://fastapi.tiangolo.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bf819b",
   "metadata": {},
   "source": [
    "Aby rozpocząć, musimy zainstalować FastAPI oraz Uvicorn, który służy jako serwer ASGI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc395f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install fastapi uvicorn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e272c23d",
   "metadata": {},
   "source": [
    "Tworzenie prostego endpointu w FastAPI . Oto podstawowy przykład, w którym endpoint HTTP GET zwraca słownik w formacie JSON."
   ]
  },
  {
   "cell_type": "raw",
   "id": "eb0c2803",
   "metadata": {},
   "source": [
    "# Plik main.py\n",
    "from fastapi import FastAPI\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "@app.get(\"/\")\n",
    "async def read_root():\n",
    "    return {\"Test\": \"API\"}"
   ]
  },
  {
   "cell_type": "raw",
   "id": "efa16145",
   "metadata": {},
   "source": [
    "# Polecenie w bashu - main oznacza, że plik main.py zawiera definicję naszej aplikacji i znajduje się w obecnym katalogu\n",
    "# --reload zapewnia restart aplikacji po zmianach w jej kodzie.\n",
    "uvicorn main:app --reload"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e38e3a25",
   "metadata": {},
   "source": [
    "# Podgląd katalogów bazowych oraz konsola po uruchomieniu aplikacji \n",
    "Directory of C:\\Users\\Marcin\\Desktop\\fastapi\n",
    "\n",
    "09.12.2023  16:46    <DIR>          .\n",
    "09.12.2023  16:46    <DIR>          ..\n",
    "09.12.2023  16:45               115 main.py\n",
    "09.12.2023  16:46    <DIR>          __pycache__\n",
    "               1 File(s)            115 bytes\n",
    "               3 Dir(s)  19 312 545 792 bytes free\n",
    "\n",
    "(base) C:\\Users\\Marcin\\Desktop\\fastapi>uvicorn main:app --reload\n",
    "\u001B[32mINFO\u001B[0m:     Will watch for changes in these directories: ['C:\\\\Users\\\\Marcin\\\\Desktop\\\\fastapi']\n",
    "\u001B[32mINFO\u001B[0m:     Uvicorn running on \u001B[1mhttp://127.0.0.1:8000\u001B[0m (Press CTRL+C to quit)\n",
    "\u001B[32mINFO\u001B[0m:     Started reloader process [\u001B[36m\u001B[1m15876\u001B[0m] using \u001B[36m\u001B[1mStatReload\u001B[0m\n",
    "\u001B[32mINFO\u001B[0m:     Started server process [\u001B[36m8764\u001B[0m]\n",
    "\u001B[32mINFO\u001B[0m:     Waiting for application startup.\n",
    "\u001B[32mINFO\u001B[0m:     Application startup complete."
   ]
  },
  {
   "cell_type": "code",
   "id": "c894ef5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T12:48:03.920387Z",
     "start_time": "2024-11-22T12:48:03.914069Z"
    }
   },
   "source": [
    "# Wykonujemy request do naszego API (na przykład możemy wykorzystać PyCharma) - domyślnie pod \n",
    "# http://127.0.0.1:8000 (widoczne powyżej: vicorn running on \u001B[1mhttp://127.0.0.1:8000\u001B[0m (Press CTRL+C to quit))\n",
    "import requests\n",
    "\n",
    "response = requests.get(\"http://127.0.0.1:8000/\")\n",
    "print(response.json())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Test': 'API'}\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbf8bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jako wyjście otrzymujemy {\"Test\": \"API\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdd7fb5",
   "metadata": {},
   "source": [
    "# Część 5: Zaawansowany Webscraping (dla zainteresowanych)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b120b1",
   "metadata": {},
   "source": [
    "Strony Dynamiczne:\n",
    "\n",
    "Strony dynamiczne wykorzystują JavaScript do ładowania treści asynchronicznie po załadowaniu głównej struktury strony. Oznacza to, że treści mogą być ładowane i zmieniane bez konieczności przeładowania całej strony."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da9de9f",
   "metadata": {},
   "source": [
    "AJAX (Asynchronous JavaScript and XML):\n",
    "\n",
    "AJAX pozwala na wymianę danych z serwerem i aktualizację części strony bez konieczności przeładowania całej strony. Jest to kluczowy element stron dynamicznych."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcb4950",
   "metadata": {},
   "source": [
    "Uwaga - Beautiful Soup i JavaScript! \n",
    "\n",
    "Beautiful Soup **nie jest** przystosowany do obsługi JavaScript. Potrafi analizować tylko statyczny kod HTML, który otrzymuje.\n",
    "W przypadku stron dynamicznych, które używają JavaScript do ładowania treści, Beautiful Soup nie będzie w stanie uzyskać dostępu do tych dynamicznie generowanych treści.\n",
    "W takich przypadkach lepszym rozwiązaniem jest użycie narzędzi takich jak Selenium, które potrafią obsługiwać JavaScript i dynamiczne treści."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5aaaecf",
   "metadata": {},
   "source": [
    "Pakiet Selenium - bardzo często wykorzystywany przy implementacji botów/crawlerów/scraperów, które pracują na stronach dynamicznych. Poniżej kilka cech zgodnie z dokumentacją:\n",
    "\n",
    "* Selenium jest narzędziem automatyzacji przeglądarek, które pozwala na interakcję ze stronami internetowymi tak, jak robiłby to prawdziwy użytkownik.\n",
    "* Selenium może uruchamiać przeglądarkę, wykonywać na niej skrypty JavaScript, kliknąć w elementy strony itp.\n",
    "* Jest to szczególnie przydatne do scrapowania stron, które silnie polegają na JavaScript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0d176f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "id": "ec4e7797",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T12:49:20.930724Z",
     "start_time": "2024-11-22T12:49:14.820743Z"
    }
   },
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://example.com\")\n",
    "# Można teraz dokonywać interakcji ze stroną, np. klikając w przyciski, wypełniając formularze itp."
   ],
   "outputs": [],
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "id": "911072a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T12:49:50.421801Z",
     "start_time": "2024-11-22T12:49:50.238362Z"
    }
   },
   "source": [
    "# Źródło strony\n",
    "print(driver.page_source)"
   ],
   "outputs": [
    {
     "ename": "NoSuchWindowException",
     "evalue": "Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=120.0.6099.71)\nStacktrace:\n0   chromedriver                        0x000000010529c4dc chromedriver + 4162780\n1   chromedriver                        0x0000000105294664 chromedriver + 4130404\n2   chromedriver                        0x0000000104eebbc0 chromedriver + 293824\n3   chromedriver                        0x0000000104ec46c0 chromedriver + 132800\n4   chromedriver                        0x0000000104f5d25c chromedriver + 758364\n5   chromedriver                        0x0000000104f71294 chromedriver + 840340\n6   chromedriver                        0x0000000104f256bc chromedriver + 530108\n7   chromedriver                        0x0000000104f26930 chromedriver + 534832\n8   chromedriver                        0x0000000105261e08 chromedriver + 3923464\n9   chromedriver                        0x00000001052663dc chromedriver + 3941340\n10  chromedriver                        0x000000010524a038 chromedriver + 3825720\n11  chromedriver                        0x0000000105266f3c chromedriver + 3944252\n12  chromedriver                        0x000000010523c6f4 chromedriver + 3770100\n13  chromedriver                        0x0000000105283980 chromedriver + 4061568\n14  chromedriver                        0x0000000105283af8 chromedriver + 4061944\n15  chromedriver                        0x00000001052942e4 chromedriver + 4129508\n16  libsystem_pthread.dylib             0x0000000190311f94 _pthread_start + 136\n17  libsystem_pthread.dylib             0x000000019030cd34 thread_start + 8\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNoSuchWindowException\u001B[0m                     Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[58], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Źródło strony\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28mprint\u001B[39m(driver\u001B[38;5;241m.\u001B[39mpage_source)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/Kurs-programowania-w-Pythonie/lib/python3.11/site-packages/selenium/webdriver/remote/webdriver.py:481\u001B[0m, in \u001B[0;36mWebDriver.page_source\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    472\u001B[0m \u001B[38;5;129m@property\u001B[39m\n\u001B[1;32m    473\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpage_source\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mstr\u001B[39m:\n\u001B[1;32m    474\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Gets the source of the current page.\u001B[39;00m\n\u001B[1;32m    475\u001B[0m \n\u001B[1;32m    476\u001B[0m \u001B[38;5;124;03m    :Usage:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    479\u001B[0m \u001B[38;5;124;03m            driver.page_source\u001B[39;00m\n\u001B[1;32m    480\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 481\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexecute(Command\u001B[38;5;241m.\u001B[39mGET_PAGE_SOURCE)[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalue\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m/opt/anaconda3/envs/Kurs-programowania-w-Pythonie/lib/python3.11/site-packages/selenium/webdriver/remote/webdriver.py:380\u001B[0m, in \u001B[0;36mWebDriver.execute\u001B[0;34m(self, driver_command, params)\u001B[0m\n\u001B[1;32m    378\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_executor\u001B[38;5;241m.\u001B[39mexecute(driver_command, params)\n\u001B[1;32m    379\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m response:\n\u001B[0;32m--> 380\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39merror_handler\u001B[38;5;241m.\u001B[39mcheck_response(response)\n\u001B[1;32m    381\u001B[0m     response[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalue\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_unwrap_value(response\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalue\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[1;32m    382\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m response\n",
      "File \u001B[0;32m/opt/anaconda3/envs/Kurs-programowania-w-Pythonie/lib/python3.11/site-packages/selenium/webdriver/remote/errorhandler.py:229\u001B[0m, in \u001B[0;36mErrorHandler.check_response\u001B[0;34m(self, response)\u001B[0m\n\u001B[1;32m    227\u001B[0m         alert_text \u001B[38;5;241m=\u001B[39m value[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124malert\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    228\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001B[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001B[39;00m\n\u001B[0;32m--> 229\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001B[0;31mNoSuchWindowException\u001B[0m: Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=120.0.6099.71)\nStacktrace:\n0   chromedriver                        0x000000010529c4dc chromedriver + 4162780\n1   chromedriver                        0x0000000105294664 chromedriver + 4130404\n2   chromedriver                        0x0000000104eebbc0 chromedriver + 293824\n3   chromedriver                        0x0000000104ec46c0 chromedriver + 132800\n4   chromedriver                        0x0000000104f5d25c chromedriver + 758364\n5   chromedriver                        0x0000000104f71294 chromedriver + 840340\n6   chromedriver                        0x0000000104f256bc chromedriver + 530108\n7   chromedriver                        0x0000000104f26930 chromedriver + 534832\n8   chromedriver                        0x0000000105261e08 chromedriver + 3923464\n9   chromedriver                        0x00000001052663dc chromedriver + 3941340\n10  chromedriver                        0x000000010524a038 chromedriver + 3825720\n11  chromedriver                        0x0000000105266f3c chromedriver + 3944252\n12  chromedriver                        0x000000010523c6f4 chromedriver + 3770100\n13  chromedriver                        0x0000000105283980 chromedriver + 4061568\n14  chromedriver                        0x0000000105283af8 chromedriver + 4061944\n15  chromedriver                        0x00000001052942e4 chromedriver + 4129508\n16  libsystem_pthread.dylib             0x0000000190311f94 _pthread_start + 136\n17  libsystem_pthread.dylib             0x000000019030cd34 thread_start + 8\n"
     ]
    }
   ],
   "execution_count": 58
  },
  {
   "cell_type": "markdown",
   "id": "c1d3aba7",
   "metadata": {},
   "source": [
    "CAPTCHA i Bot Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febe5e68",
   "metadata": {},
   "source": [
    "* UWAGA: Zawsze przestrzegaj zasad i warunków korzystania ze strony!\n",
    "\n",
    "* Scrapowanie możemy rozpocząć tylko wtedy, gdy mamy zgodę właściciela treści, administratora serwera, strony lub strona zezwala na automatyzację zapytań.\n",
    "\n",
    "* Strony internetowe często używają CAPTCHA i mechanizmów wykrywania botów, aby zapobiec automatycznemu scrapowaniu i innym formom nadużyć.\n",
    "\n",
    "* Automatyczne obejście CAPTCHA i mechanizmów wykrywania botów może naruszać warunki korzystania z serwisu i być nieetyczne.\n",
    "\n",
    "* Do dużych projektów programistycznych można wykorzystać również pakiet scrapy, który z wykorzystaniem scrapy.Spider pozwala na budowę zaawansowanych scraperów."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
